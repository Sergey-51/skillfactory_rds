# SkillFactory DataScience
 
## Module_6: Выбираем авто выгодно. 

## УСЛОВИЯ

![image](https://user-images.githubusercontent.com/78755876/145105518-e1b10713-5f2c-4b08-bf6e-da8a4ea8d82d.png)

* Вы работаете в компании, которая занимается продажей автомобилей с пробегом в Москве. 
* Основная задача компании и её менеджеров — максимально быстро находить выгодные предложения (проще говоря, купить ниже рынка, а продать дороже рынка). 
* Руководство компании просит вашу команду создать модель, которая будет предсказывать стоимость автомобиля по его характеристикам.
* Если такая модель будет работать хорошо, то вы сможете быстро выявлять выгодные предложения (когда желаемая цена продавца ниже предсказанной рыночной цены). Это значительно ускорит работу менеджеров и повысит прибыль компании.

## Задачи: 
* Спасить данные для обучающей выборки.
* Совместить два разных набора данных (обучающий и тестовый).
* Попробовать разные методы регрессии.
* Попробовать реализовать стекинг.
* Превзойти результат baseline.

# Результат и выводы

## Краткая информацию о данных
* Данные о автомобиле содержали более 20 признаков.
* В качестве скоринга необходимо улучшить MAPE - Mean absolute percentage error (меньше значение = лучше предсказание). 
* Сами спарсенные данные приложить не получилось - размер файлов слишком большой.
* В папке находится три файла:
   *   [01-F-Parsing.ipynb](https://github.com/Sergey-51/skillfactory_rds/blob/master/Module_6/01-F-Parsing.ipynb) Jupyter Notebook с парсингом auto.ru
   *   [02-F-Clearing Data.ipynb](https://github.com/Sergey-51/skillfactory_rds/blob/master/Module_6/02-F-Clearing%20Data.ipynb) Jupyter Notebook с первичным знакомством с данными
   *   [03-F-Modelling.ipynb](https://github.com/Sergey-51/skillfactory_rds/blob/master/Module_6/03-F-Modelling.ipynb) Финальный Jupyter Notebook с моделированием.

## Результаты (что было проделано)
* Был реализован парсинг сайта auto.ru (был опробован парсинг через html и json, остановился на первом, тк json давал не полные данные (но скорее всего я не до разобрался с форматом))
* По результату пришлось перепарсить данные (хорошо, что я сохранил все ответы сервера по каждой ссылке, поэтому второй раз парсинг прошел гораздо быстрее), для этого пришлось писать вспомогательный ноутбук.
* В отдельном ноутбуке произвел предварительный анализ полученных данных с сайта (получается такое углубленное знакомство, пока парсились основные данные)
* Написаны вспомогательные функции для упрощения перезагрузки исходных данных.
* Пришлось сравнивать данные между полученными данными для обучения (train) и имеющимся тестовым набором (test).
* Попробовал использовать pandas_profiling (файлы находятся в папке data).
* Поэкспериментировал с onehotencoding (сгоряча написал свой кодировщик категориальных признаков).
* Реализовал стекинг итоговый результат: MAPE=13.76%, Public LB=15.57091 и 97 место на лидерборде

## Что еще можно было бы сделать?
* Спарсить больше данных (спарсить успел, но не успел обработать их более 98'000 объявлений).
* Можно распараллелить парсинг.
* Была мысль, что раз нам в тестовом наборе дали ссылки на объявления, то это не спроста и можно было попробовать спарсить неудаленные объявления и дополнить общий надор данных новыми признаками.
* Посмотреть, что можно извлечь из признаков или как еще можно обработать признаки.
* Можно было еще поработать с scaler, попробовать разные алгоритмы.
* Потратить больше времени на подбор гиперпараметров для моделей и после этого сравнить уже длучше моджели с лучшими и собрать из них стекинг.

## Что понравилось?
* парсинг действительно сильно затягивает (тому кто это читает - будте окуратнее, время очень много уходит)
* оказалось не так легко объединить train и test, видимо так было задумано. Пришлось проходить по всем признакам внимательно.
* EDA как всегда - его просто много, а мало никогда и не будет.

## Что НЕ понравилось?
* мои собственные технические проблемы с jupyter-ом (как специально перед сдачей проекта перестала работать pandas_profiling, CatBoost тоже слег в ночь перед сдачей((). Отсюда сделал вывод - надо учиться делать виртуальное окружение и работать в нём (плюс если вы в команде, то так точно будет легче работать - на одинаковых версиях библиотек). 
