# SkillFactory DataScience
 
## Module_6: Выбираем авто выгодно. 

<img src="https://user-images.githubusercontent.com/78755876/145107275-290d5fd7-b337-4fef-a418-cd300c20b805.png" width="600" height="300" align="left"/><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>

## УСЛОВИЯ

<img src="https://user-images.githubusercontent.com/78755876/145105518-e1b10713-5f2c-4b08-bf6e-da8a4ea8d82d.png" width="350" height="250" align="left"/><br><br><br><br><br><br><br><br><br><br><br><br>

* Вы работаете в компании, которая занимается продажей автомобилей с пробегом в Москве. 
* Основная задача компании и её менеджеров — максимально быстро находить выгодные предложения (проще говоря, купить ниже рынка, а продать дороже рынка). 
* Руководство компании просит вашу команду создать модель, которая будет предсказывать стоимость автомобиля по его характеристикам.
* Если такая модель будет работать хорошо, то вы сможете быстро выявлять выгодные предложения (когда желаемая цена продавца ниже предсказанной рыночной цены). Это значительно ускорит работу менеджеров и повысит прибыль компании.

<code style="background:yellow;color:black"><b>ПРОБЛЕМА.</b> Только вот незадача: исторически сложилось, что компания изначально не собирала данные. Есть только небольшой датасет с историей продаж за короткий период, которого для обучения модели будет явно мало. Его мы будем использовать для теста, остальное придется собрать самим.</code>

## Инструменты.
* страница [соревнования](https://www.kaggle.com/account/login?ReturnUrl=%2Ft%2F841c9bc848214c9d82c7628b7d345d56) на <i>kaggle</i>
* К этому соревнованию доступно базовое решение ([Baseline](https://www.kaggle.com/itslek/baseline-sf-dst-car-price-prediction-v16)).

## Задачи: 
* Спасить данные для обучающей выборки.
* Совместить два разных набора данных (обучающий и тестовый).
* Попробовать разные методы регрессии.
* Попробовать реализовать стекинг.
* Превзойти результат baseline (на момент сдачи проекта это было 214 место и 30.92228 баллов).

# Результат и выводы

## Краткая информацию о данных
* Данные о автомобиле содержали более 20 признаков.
* В качестве скоринга необходимо улучшить MAPE - Mean absolute percentage error (меньше значение = лучше предсказание). 
* Сами спарсенные данные приложить не получилось - размер файлов слишком большой.
* В папке находится четыре файла:
   *   [01-F-Parsing.ipynb](https://github.com/Sergey-51/skillfactory_rds/blob/master/Module_6/01-F-Parsing.ipynb) Jupyter Notebook с парсингом auto.ru
   *   [02-F-Clearing Data.ipynb](https://github.com/Sergey-51/skillfactory_rds/blob/master/Module_6/02-F-Clearing%20Data.ipynb) Jupyter Notebook с первичным знакомством с данными
   *   [03-F-Modelling.ipynb](https://github.com/Sergey-51/skillfactory_rds/blob/master/Module_6/03-F-Modelling.ipynb) Финальный Jupyter Notebook с моделированием.
   *   [submission 15-57091.csv](https://github.com/Sergey-51/skillfactory_rds/blob/master/Module_6/submission%2015-57091.csv) итоговый файл submission.csv

## Результаты (что было проделано)
* Был реализован парсинг сайта auto.ru (был опробован парсинг через html и json, остановился на первом, тк json давал не полные данные (но скорее всего я не до разобрался с форматом))
* По результату пришлось перепарсить данные (хорошо, что я сохранил все ответы сервера по каждой ссылке, поэтому второй раз парсинг прошел гораздо быстрее), для этого пришлось писать вспомогательный ноутбук.
* В отдельном ноутбуке произвел предварительный анализ полученных данных с сайта (получается такое углубленное знакомство, пока парсились основные данные)
* Написаны вспомогательные функции для упрощения перезагрузки исходных данных.
* Пришлось сравнивать данные между полученными данными для обучения (train) и имеющимся тестовым набором (test).
* Попробовал использовать pandas_profiling (файлы находятся в папке data).
* Поэкспериментировал с onehotencoding (сгоряча написал свой кодировщик категориальных признаков).
* В результате получил MAPE=13.76% и 15.57091 баллов на Public LB -> 97 место на лидерборде [результат](https://twitter.com/intent/tweet?text=Rank%2097%20on%20%23kaggle.%20I%27ll%20sleep%20when%20I%27m%20dead.%20https%3A%2F%2Fkaggle.com%2Fc%2Fsf-dst-car-price-prediction)

## Что еще можно было бы сделать?
* Спарсить больше данных (спарсить успел, но не успел обработать их более 98'000 объявлений).
* Можно распараллелить парсинг.
* Была мысль, что раз нам в тестовом наборе дали ссылки на объявления, то это не спроста и можно было попробовать спарсить неудаленные объявления и дополнить общий надор данных новыми признаками.
* Посмотреть, что можно извлечь из признаков или как еще можно обработать признаки.
* Можно было еще поработать с scaler, попробовать разные алгоритмы.
* Потратить больше времени на подбор гиперпараметров для моделей и после этого сравнить уже длучше моджели с лучшими и собрать из них стекинг.

## Что понравилось?
* парсинг действительно сильно затягивает (тому кто это читает - будте окуратнее, время очень много уходит)
* оказалось не так легко объединить train и test, видимо так было задумано. Пришлось проходить по всем признакам внимательно.
* EDA как всегда - его просто много, а мало никогда и не будет.

## Что НЕ понравилось?
* мои собственные технические проблемы с jupyter-ом (как специально перед сдачей проекта перестала работать pandas_profiling, CatBoost тоже слег в ночь перед сдачей((). Отсюда сделал вывод - надо учиться делать виртуальное окружение и работать в нём (плюс если вы в команде, то так точно будет легче работать - на одинаковых версиях библиотек). 
* Плюс, чуть не потерялись два уже полностью оформленных файла... - вывод надо скидывать на github не в последний момент (в идеале посмотреть как это можно упростить из python-а).
