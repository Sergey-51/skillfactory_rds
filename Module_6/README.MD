# SkillFactory DataScience
 
## Module_6: Разведывательный анализ данных (Exploratory data analysis) + Feature Engineering (FE) + ML, предсказание цены, градиентный бустинг и стекинг, API, работа с текстом 

## Задачи: 
* Спасить данные для обучающей выборки.
* Совместить два разных набора данных (обучающий и тестовый).
* Попробовать разные методы регрессии.
* Попробовать реализовать стекинг.
* Превзойти результат baseline.

# Результат и выводы

## Краткая информацию о данных
* Данные о автомобиле содержали более 20 признаков.
* Нужно предсказать стоимость автомобиля из тестовой выборки на основе спарсенных данных.
* В качестве скоринга необходимо улучшить MAPE - Mean absolute percentage error (меньше значение = лучше предсказание). 

## Результаты (что было проделано)
* Был реализован парсинг сайта auto.ru (был опробован парсинг через html и json, остановился на первом, тк json давал не полные данные (но скорее всего я не до разобрался с форматом))
* По результату пришлось перепарсить данные (хорошо, что я сохранил все ответы сервера по каждой ссылке, поэтому второй раз парсинг прошел гораздо быстрее), для этого пришлось писать вспомогательный ноутбук.
* В отдельном ноутбуке произвел предварительный анализ полученных данных с сайта (получается такое углубленное знакомство, пока парсились основные данные)
* Написаны вспомогательные функции для упрощения перезагрузки исходных данных.
* Пришлось сравнивать данные между полученными данными для обучения (train) и имеющимся тестовым набором (test).
* Попробовал использовать pandas_profiling (файлы находятся в папке data).
* Поэкспериментировал с onehotencoding (сгоряча написал свой кодировщик категориальных признаков).
* Реализовал стекинг итоговый результат: MAPE=13.76%, Public LB=15.57091 и 97 место на лидерборде

## Что еще можно было бы сделать?
* Спарсить больше данных (спарсить успел, но не успел обработать их более 98'000 объявлений).
* Была мысль, что раз нам в тестовом наборе дали ссылки на объявления, то это не спроста и можно было попробовать спарсить неудаленные объявления и дополнить общий надор данных новыми признаками.
* Посмотреть, что можно извлечь из признаков или как еще можно обработать признаки.
* Можно было еще поработать с scaler, попробовать разные алгоритмы.
* Потратить больше времени на подбор гиперпараметров для моделей и после этого сравнить уже длучше моджели с лучшими и собрать из них стекинг.

## Что понравилось?
* парсинг действительно сильно затягивает (тому кто это читает - будте окуратнее, время очень много уходит)
* оказалось не так легко объединить train и test, видимо так было задумано. Пришлось проходить по всем признакам внимательно.
* EDA как всегда - его просто много, а мало никогда и не будет.

## Что НЕ понравилось?
* мои собственные технические проблемы с jupyter-ом (как специально перед сдачей проекта перестала работать pandas_profiling). Отсюда сделал вывод - надо учиться делать виртуальное окружение и работать в нём (плюс если вы в команде, то так точно будет легче работать - на одинаковых версиях библиотек). 
* вапва
